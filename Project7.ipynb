{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eina-lCD2GrH"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io   \n",
    "import h5py\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "%tensorflow_version 2.x\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "1JmzH9zzBCDh",
    "outputId": "34cec1d6-ae66-4ef2-80db-b96d11efa180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AyKnI2ZUcVPj"
   },
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G97HABChFmuw"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "h5f = h5py.File('/content/drive/My Drive/Deep Learning/Project 7 NN/Dataset/SVHN_single_grey1.h5','r')\n",
    "\n",
    "X_train = h5f['X_train'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "\n",
    "X_val = h5f['X_test'][:]\n",
    "y_val = h5f['y_test'][:]\n",
    "\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_CWlCsF9clrW"
   },
   "source": [
    "Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "aGlmGJnpckyb",
    "outputId": "66e80d3c-a58d-49b2-d66a-88d0569714de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (42000, 1024) (42000,)\n",
      "Test set (18000, 1024) (18000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 1024)\n",
    "X_val = X_val.reshape(X_val.shape[0], 1024)\n",
    "\n",
    "X_train = X_train/255.0\n",
    "X_val = X_val/255.0\n",
    "\n",
    "print('Training set', X_train.shape, y_train.shape)\n",
    "print('Test set', X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKd2es5xgbRM"
   },
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "Kr0HN8UDf9px",
    "outputId": "785972ff-df68-422c-fbf4-9d270fd1506c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44026133"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "I3eBqAdVf99v",
    "outputId": "8cc94052-a773-42fd-8235-3c852c33e63b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4985952380952385"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "IUv8MU4of9Xi",
    "outputId": "cc996e67-2228-4338-de1a-9b7854929ae0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44174716"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "1tQRNWXkgnfe",
    "outputId": "3d085243-9beb-4918-831d-bdae6b4f0829"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.503277777777778"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "id": "QlkIUVs9dKdB",
    "outputId": "0faceb8f-9c71-4e8c-d0c3-e431bc85baa9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAA9CAYAAACpzLMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhqM4BwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image: [2 6 7 4 4 0 3 0 7 3]\n"
     ]
    }
   ],
   "source": [
    "# visualizing the first 10 images in the dataset and their labels\n",
    "\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i].reshape(32, 32), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('label for each of the above image: %s' % (y_train[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "U1nFw3JfdKXm",
    "outputId": "9ddc3822-0a28-49b2-9662-63cbc66b6a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024) (18000, 1024) (42000,) (18000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "qgNKewBOdKS7",
    "outputId": "50903597-59ed-40f9-f4ef-ebdb593ea99a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12968785, 0.11866706, 0.10530196, ..., 0.19477727, 0.19942354,\n",
       "       0.20799099], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "wu2dPXPRVbYu",
    "outputId": "4d1528b0-228d-407a-a0cb-218bab787f1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "sGPzZUkHFqHc",
    "outputId": "5dcd05fa-aa13-4dcd-94bc-b53d0e358e91"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmSBnFyIT5OxCZIKcXYhMkLMLkQn/BhbqT4CABHqVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  1\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_val[0])    # show first number in the dataset\n",
    "plt.show()\n",
    "print('Label: ', y_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ww5WSfQGr4wc"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hupEnmFtjmQX"
   },
   "source": [
    "**KNN Classifier**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SZgKaAc2M2GX",
    "outputId": "9604c28f-8c0b-4039-c74a-1801229b11fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32416666666666666"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2udWHYhjrAo"
   },
   "source": [
    "Finding the optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "ViramRdTM14R",
    "outputId": "67fb8db2-caf3-4894-b984-0e257fca9888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K value = 3 Accuracy = 0.3783888888888889\n",
      "K value = 7 Accuracy = 0.28683333333333333\n",
      "K value = 11 Accuracy = 0.23622222222222222\n",
      "K value = 15 Accuracy = 0.201\n",
      "The optimal number of neighbors is 3\n"
     ]
    }
   ],
   "source": [
    "#List of values for n_neigbours (k)\n",
    "neighbours = [3,7,11,15]\n",
    "\n",
    "ac_scores = []\n",
    "\n",
    "for k in neighbours:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores = knn.score(X_val, y_val)\n",
    "    print(\"K value = {} Accuracy = {}\".format(k, scores))\n",
    "    ac_scores.append(scores)\n",
    "\n",
    "MSE = [1 - x for x in ac_scores]\n",
    "\n",
    "optimal_k = neighbours[MSE.index(min(MSE))]\n",
    "print(\"The optimal number of neighbors is %d\" % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrOg7wSbFf6W"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "H9aGEHWMFgWm",
    "outputId": "73868042-59a5-44c3-bc23-455f20a50da7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFI3MAY_Fg3a"
   },
   "outputs": [],
   "source": [
    "y_predict = knn.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8nFZvhMvjv67"
   },
   "source": [
    "Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "23_3gEAmG0vt",
    "outputId": "d67efaf4-2bbe-4800-8682-e5ba1f74ab39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.68      0.46      1814\n",
      "           1       0.40      0.71      0.52      1828\n",
      "           2       0.49      0.54      0.51      1803\n",
      "           3       0.35      0.38      0.36      1719\n",
      "           4       0.60      0.56      0.58      1812\n",
      "           5       0.45      0.32      0.37      1768\n",
      "           6       0.48      0.31      0.38      1832\n",
      "           7       0.78      0.55      0.64      1808\n",
      "           8       0.45      0.25      0.32      1812\n",
      "           9       0.60      0.32      0.41      1804\n",
      "\n",
      "    accuracy                           0.46     18000\n",
      "   macro avg       0.49      0.46      0.46     18000\n",
      "weighted avg       0.50      0.46      0.46     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_val, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BqVKatkQijt8"
   },
   "source": [
    "**Nerural Network**\n",
    "\n",
    "We will build a Neural Network, improving the accuracy in every step by trying different combinations.\n",
    "\n",
    "Model 1: Naive MLP model without any alterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lh4tlmb6G00d",
    "outputId": "7068f7cc-bc03-47b1-c2aa-973b603f2e01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 2.3087 - accuracy: 0.1149\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.2941 - accuracy: 0.1244\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.2809 - accuracy: 0.1457\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2666 - accuracy: 0.1756\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.2508 - accuracy: 0.2070\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.2324 - accuracy: 0.2340\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.2117 - accuracy: 0.2561\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.1889 - accuracy: 0.2822\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.1640 - accuracy: 0.3067\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.1364 - accuracy: 0.3254\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.1065 - accuracy: 0.3432\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.0748 - accuracy: 0.3619\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.0409 - accuracy: 0.3826\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.0064 - accuracy: 0.3989\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.9709 - accuracy: 0.4164\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.9352 - accuracy: 0.4335\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.8993 - accuracy: 0.4494\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.8640 - accuracy: 0.4577\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.8289 - accuracy: 0.4700\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.7945 - accuracy: 0.4860\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.7613 - accuracy: 0.4976\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.7290 - accuracy: 0.5085\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.6979 - accuracy: 0.5186\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.6681 - accuracy: 0.5285\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.6387 - accuracy: 0.5386\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.6108 - accuracy: 0.5466\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.5835 - accuracy: 0.5543\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.5575 - accuracy: 0.5642\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.5328 - accuracy: 0.5718\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.5086 - accuracy: 0.5815\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.4857 - accuracy: 0.5886\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.4636 - accuracy: 0.5951\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.4429 - accuracy: 0.6009\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.4225 - accuracy: 0.6080\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.4033 - accuracy: 0.6141\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 1.3847 - accuracy: 0.6190\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.3669 - accuracy: 0.6245\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.3503 - accuracy: 0.6297\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.3340 - accuracy: 0.6346\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.3186 - accuracy: 0.6381\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.3037 - accuracy: 0.6416\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2896 - accuracy: 0.6459\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 1.2763 - accuracy: 0.6491\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2629 - accuracy: 0.6523\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2501 - accuracy: 0.6555\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2381 - accuracy: 0.6591\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2274 - accuracy: 0.6611\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2158 - accuracy: 0.6635\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2060 - accuracy: 0.6660\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 1.1952 - accuracy: 0.6682\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1855 - accuracy: 0.6706\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1757 - accuracy: 0.6718\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1677 - accuracy: 0.6741\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1588 - accuracy: 0.6753\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1505 - accuracy: 0.6776\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1428 - accuracy: 0.6798\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1349 - accuracy: 0.6805\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 1.1274 - accuracy: 0.6832\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1208 - accuracy: 0.6848\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 1.1133 - accuracy: 0.6865\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1069 - accuracy: 0.6857\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1003 - accuracy: 0.6882\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0943 - accuracy: 0.6896\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0881 - accuracy: 0.6913\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0812 - accuracy: 0.6929\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 1.0764 - accuracy: 0.6934\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0701 - accuracy: 0.6942\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0650 - accuracy: 0.6975\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0599 - accuracy: 0.6977\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0547 - accuracy: 0.6984\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0494 - accuracy: 0.7010\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0448 - accuracy: 0.7030\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0403 - accuracy: 0.7019\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0352 - accuracy: 0.7041\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0301 - accuracy: 0.7056\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0263 - accuracy: 0.7059\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0213 - accuracy: 0.7073\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0165 - accuracy: 0.7100\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0123 - accuracy: 0.7095\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0089 - accuracy: 0.7102\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0043 - accuracy: 0.7116\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0000 - accuracy: 0.7134\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 0.9966 - accuracy: 0.7135\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9926 - accuracy: 0.7148\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9887 - accuracy: 0.7154\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9844 - accuracy: 0.7182\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9811 - accuracy: 0.7190\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9773 - accuracy: 0.7190\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9732 - accuracy: 0.7199\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9697 - accuracy: 0.7214\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9668 - accuracy: 0.7229\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9632 - accuracy: 0.7225\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9599 - accuracy: 0.7243\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9566 - accuracy: 0.7247\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9532 - accuracy: 0.7257\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9503 - accuracy: 0.7259\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9472 - accuracy: 0.7293\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9443 - accuracy: 0.7288\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9410 - accuracy: 0.7284\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9384 - accuracy: 0.7301\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape = (1024, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "_mBSxr--G04T",
    "outputId": "f7b071ea-9c2b-4f33-9b53-96225ce8068d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 70us/sample - loss: 0.9682 - accuracy: 0.7209\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "2flJ2twoI5ph",
    "outputId": "ca63d7fa-4f6c-4143-a51a-e5f671603374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  72.09 %\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', round(results[1]*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EK8Dd0ciiy9U"
   },
   "source": [
    "Model 2\n",
    "\n",
    "NN with more hidden layers and ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "G3a6hN4KI9Pc",
    "outputId": "e9e2849f-ced8-4b51-9406-0f74a4c29043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 2.3041 - accuracy: 0.1008\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2992 - accuracy: 0.1110\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.2953 - accuracy: 0.1203\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2908 - accuracy: 0.1337\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2852 - accuracy: 0.1510\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2782 - accuracy: 0.1690\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2691 - accuracy: 0.1909\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2577 - accuracy: 0.2096\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2435 - accuracy: 0.2292\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2249 - accuracy: 0.2537\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.2004 - accuracy: 0.2763\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.1664 - accuracy: 0.2932\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.1222 - accuracy: 0.3142\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.0669 - accuracy: 0.3290\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.0023 - accuracy: 0.3497\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.9342 - accuracy: 0.3708\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.8639 - accuracy: 0.3924\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.7968 - accuracy: 0.4145\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.7348 - accuracy: 0.4325\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.6755 - accuracy: 0.4549\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.6245 - accuracy: 0.4714\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.5729 - accuracy: 0.4947\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.5224 - accuracy: 0.5146\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.4811 - accuracy: 0.5294\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.4399 - accuracy: 0.5442\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.4203 - accuracy: 0.5468\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.3791 - accuracy: 0.5682\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.3569 - accuracy: 0.5731\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.3314 - accuracy: 0.5790\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.3099 - accuracy: 0.5878\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2859 - accuracy: 0.5956\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.2732 - accuracy: 0.6018\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.2528 - accuracy: 0.6075\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2375 - accuracy: 0.6131\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.2197 - accuracy: 0.6210\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2061 - accuracy: 0.6228\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1884 - accuracy: 0.6290\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1864 - accuracy: 0.6311\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1662 - accuracy: 0.6363\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1506 - accuracy: 0.6421\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1466 - accuracy: 0.6449\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1345 - accuracy: 0.6480\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1151 - accuracy: 0.6549\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1116 - accuracy: 0.6564\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0975 - accuracy: 0.6612\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0874 - accuracy: 0.6645\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0844 - accuracy: 0.6655\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0739 - accuracy: 0.6690\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0657 - accuracy: 0.6723\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0540 - accuracy: 0.6756\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0480 - accuracy: 0.6766\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0405 - accuracy: 0.6795\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0280 - accuracy: 0.6868\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0189 - accuracy: 0.6876\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0106 - accuracy: 0.6879\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0074 - accuracy: 0.6897\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9974 - accuracy: 0.6939\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9929 - accuracy: 0.6956\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9851 - accuracy: 0.6985\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9788 - accuracy: 0.6992\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9749 - accuracy: 0.7005\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9654 - accuracy: 0.7049\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9561 - accuracy: 0.7073\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9537 - accuracy: 0.7063\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9476 - accuracy: 0.7103\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9409 - accuracy: 0.7126\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9359 - accuracy: 0.7135\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9309 - accuracy: 0.7166\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9233 - accuracy: 0.7166\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9200 - accuracy: 0.7189\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9143 - accuracy: 0.7227\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9097 - accuracy: 0.7200\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9070 - accuracy: 0.7228\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8999 - accuracy: 0.7248\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8975 - accuracy: 0.7256\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8922 - accuracy: 0.7282\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8925 - accuracy: 0.7255\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8846 - accuracy: 0.7289\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8847 - accuracy: 0.7288\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8752 - accuracy: 0.7330\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8743 - accuracy: 0.7313\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8658 - accuracy: 0.7372\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8670 - accuracy: 0.7355\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8641 - accuracy: 0.7372\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8606 - accuracy: 0.7355\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8508 - accuracy: 0.7413\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8472 - accuracy: 0.7419\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8411 - accuracy: 0.7430\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8425 - accuracy: 0.7430\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8351 - accuracy: 0.7451\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8330 - accuracy: 0.7467\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8251 - accuracy: 0.7495\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8315 - accuracy: 0.7465\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8229 - accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8221 - accuracy: 0.7495\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8161 - accuracy: 0.7523\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8120 - accuracy: 0.7540\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8138 - accuracy: 0.7527\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8098 - accuracy: 0.7526\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8041 - accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape = (1024, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "dM0nUgJ9JEV-",
    "outputId": "666cb710-12d6-46f2-e2d2-2fa67025c206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 69us/sample - loss: 0.8956 - accuracy: 0.7342\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "gezo9zr1JqE0",
    "outputId": "1f214b91-ffbb-48e3-f0c4-a3362dea2f8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  73.42 %\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', round(results[1]*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGMda7Sej9P-"
   },
   "source": [
    "Model 3: Changing Number of activators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MQx6tWkXF-a8",
    "outputId": "04b7dae7-e37f-4a7e-dda3-2d5bf8566ca2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.3036 - accuracy: 0.1113\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.2941 - accuracy: 0.1283\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.2874 - accuracy: 0.1431\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2789 - accuracy: 0.1631\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2680 - accuracy: 0.1833\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2539 - accuracy: 0.2061\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.2349 - accuracy: 0.2219\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2092 - accuracy: 0.2390\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.1751 - accuracy: 0.2593\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.1326 - accuracy: 0.2762\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.0824 - accuracy: 0.2930\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.0291 - accuracy: 0.3181\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.9738 - accuracy: 0.3451\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.9171 - accuracy: 0.3654\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.8617 - accuracy: 0.3897\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.8031 - accuracy: 0.4125\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.7422 - accuracy: 0.4364\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.6851 - accuracy: 0.4622\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.6283 - accuracy: 0.4839\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.5778 - accuracy: 0.5023\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.5290 - accuracy: 0.5166\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.4883 - accuracy: 0.5277\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.4439 - accuracy: 0.5446\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.4061 - accuracy: 0.5551\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 1.3820 - accuracy: 0.5664\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 1.3466 - accuracy: 0.5775\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.3257 - accuracy: 0.5869\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.3063 - accuracy: 0.5936\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.2815 - accuracy: 0.6020\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.2705 - accuracy: 0.6025\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2492 - accuracy: 0.6128\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2362 - accuracy: 0.6170\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2183 - accuracy: 0.6219\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2061 - accuracy: 0.6256\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1922 - accuracy: 0.6320\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1836 - accuracy: 0.6333\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1654 - accuracy: 0.6412\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1612 - accuracy: 0.6406\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1453 - accuracy: 0.6469\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1450 - accuracy: 0.6454\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1293 - accuracy: 0.6507\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1200 - accuracy: 0.6531\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1095 - accuracy: 0.6586\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1017 - accuracy: 0.6588\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0918 - accuracy: 0.6639\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0895 - accuracy: 0.6618\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0771 - accuracy: 0.6679\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0718 - accuracy: 0.6691\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0638 - accuracy: 0.6736\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0602 - accuracy: 0.6721\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0511 - accuracy: 0.6742\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0377 - accuracy: 0.6796\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0341 - accuracy: 0.6823\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0275 - accuracy: 0.6851\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0213 - accuracy: 0.6853\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0151 - accuracy: 0.6888\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0057 - accuracy: 0.6900\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0019 - accuracy: 0.6930\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9908 - accuracy: 0.6964\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9853 - accuracy: 0.6982\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9789 - accuracy: 0.6989\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9661 - accuracy: 0.7016\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9641 - accuracy: 0.7050\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9609 - accuracy: 0.7069\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9547 - accuracy: 0.7066\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9445 - accuracy: 0.7104\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9389 - accuracy: 0.7127\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9322 - accuracy: 0.7162\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9247 - accuracy: 0.7180\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9226 - accuracy: 0.7180\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9154 - accuracy: 0.7213\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9091 - accuracy: 0.7234\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9041 - accuracy: 0.7255\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8992 - accuracy: 0.7259\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8936 - accuracy: 0.7279\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8882 - accuracy: 0.7309\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8894 - accuracy: 0.7303\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8764 - accuracy: 0.7344\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.8728 - accuracy: 0.7338\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8795 - accuracy: 0.7329\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8668 - accuracy: 0.7363\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8583 - accuracy: 0.7393\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8502 - accuracy: 0.7418\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8473 - accuracy: 0.7426\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8414 - accuracy: 0.7445\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8399 - accuracy: 0.7458\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8361 - accuracy: 0.7466\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8301 - accuracy: 0.7475\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8289 - accuracy: 0.7499\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8229 - accuracy: 0.7522\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8219 - accuracy: 0.7520\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8111 - accuracy: 0.7560\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8060 - accuracy: 0.7563\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8106 - accuracy: 0.7559\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8057 - accuracy: 0.7558\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7993 - accuracy: 0.7584\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7903 - accuracy: 0.7608\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7897 - accuracy: 0.7618\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7860 - accuracy: 0.7631\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7880 - accuracy: 0.7618\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(70, input_shape = (1024, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(30))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "JzkgaHCgF-j_",
    "outputId": "021df6ed-eb34-48be-f1a3-5556824ee60d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 67us/sample - loss: 0.8511 - accuracy: 0.7439\n",
      "Test accuracy:  74.39 %\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)\n",
    "print('Test accuracy: ', round(results[1]*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amQ6aHVkkICr"
   },
   "source": [
    "Model 4: With Weight Initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XfBaG4yMF-oQ",
    "outputId": "0bf3465e-cc45-4b6a-c03a-a45208252182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.3457 - accuracy: 0.1143\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2921 - accuracy: 0.1314\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2659 - accuracy: 0.1556\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 2.2381 - accuracy: 0.1756\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.2016 - accuracy: 0.2003\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.1586 - accuracy: 0.2234\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.1091 - accuracy: 0.2417\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 2.0576 - accuracy: 0.2645\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 2.0022 - accuracy: 0.2862\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.9444 - accuracy: 0.3082\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.8789 - accuracy: 0.3376\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.8337 - accuracy: 0.3570\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.7704 - accuracy: 0.3884\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.7205 - accuracy: 0.4104\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.6659 - accuracy: 0.4380\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.6176 - accuracy: 0.4584\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.5615 - accuracy: 0.4874\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.5201 - accuracy: 0.5046\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.4779 - accuracy: 0.5219\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.4465 - accuracy: 0.5338\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.4045 - accuracy: 0.5500\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.3792 - accuracy: 0.5608\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.3439 - accuracy: 0.5753\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.3176 - accuracy: 0.5861\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2911 - accuracy: 0.5950\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.2730 - accuracy: 0.6006\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2440 - accuracy: 0.6127\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.2295 - accuracy: 0.6164\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.2015 - accuracy: 0.6287\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1846 - accuracy: 0.6337\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1646 - accuracy: 0.6410\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1531 - accuracy: 0.6440\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.1382 - accuracy: 0.6515\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1216 - accuracy: 0.6541\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.1127 - accuracy: 0.6579\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0988 - accuracy: 0.6626\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0891 - accuracy: 0.6664\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0723 - accuracy: 0.6715\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0697 - accuracy: 0.6717\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0571 - accuracy: 0.6768\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 1.0472 - accuracy: 0.6826\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0384 - accuracy: 0.6826\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0292 - accuracy: 0.6864\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0168 - accuracy: 0.6911\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0113 - accuracy: 0.6904\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 1.0039 - accuracy: 0.6941\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9976 - accuracy: 0.6965\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.9898 - accuracy: 0.6997\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.9790 - accuracy: 0.7036\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9677 - accuracy: 0.7065\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9665 - accuracy: 0.7087\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9597 - accuracy: 0.7098\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.9513 - accuracy: 0.7108\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9463 - accuracy: 0.7140\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9383 - accuracy: 0.7163\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.9329 - accuracy: 0.7169\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9284 - accuracy: 0.7191\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9198 - accuracy: 0.7233\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.9198 - accuracy: 0.7216\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9094 - accuracy: 0.7233\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.9015 - accuracy: 0.7272\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9024 - accuracy: 0.7257\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9022 - accuracy: 0.7255\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8933 - accuracy: 0.7287\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8843 - accuracy: 0.7316\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8797 - accuracy: 0.7333\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8758 - accuracy: 0.7352\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8693 - accuracy: 0.7370\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8628 - accuracy: 0.7385\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8577 - accuracy: 0.7413\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8562 - accuracy: 0.7406\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8533 - accuracy: 0.7412\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8450 - accuracy: 0.7447\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8468 - accuracy: 0.7438\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8384 - accuracy: 0.7474\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.8385 - accuracy: 0.7453\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.8355 - accuracy: 0.7466\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8240 - accuracy: 0.7505\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8254 - accuracy: 0.7509\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8176 - accuracy: 0.7530\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8170 - accuracy: 0.7525\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8114 - accuracy: 0.7534\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8070 - accuracy: 0.7555\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8091 - accuracy: 0.7557\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.7972 - accuracy: 0.7589\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8010 - accuracy: 0.7569\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7978 - accuracy: 0.7590\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7892 - accuracy: 0.7619\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7849 - accuracy: 0.7624\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7832 - accuracy: 0.7625\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7829 - accuracy: 0.7634\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7774 - accuracy: 0.7660\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7734 - accuracy: 0.7667\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7743 - accuracy: 0.7653\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.7754 - accuracy: 0.7678\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7651 - accuracy: 0.7697\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7637 - accuracy: 0.7683\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7617 - accuracy: 0.7693\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.7549 - accuracy: 0.7729\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.7549 - accuracy: 0.7726\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(70, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(30, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "jqikbxH7F-zs",
    "outputId": "45582c0f-8129-41e6-fe48-9c23d28053f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 67us/sample - loss: 0.8066 - accuracy: 0.7633\n",
      "Test accuracy:  76.33 %\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)\n",
    "print('Test accuracy: ', round(results[1]*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YJF2DxykQx8"
   },
   "source": [
    "Model 5: Adding Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "v5eLqkfpF-xt",
    "outputId": "79726cbf-a19c-4869-9c3c-1034a2b5b014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 2.3311 - accuracy: 0.1772\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.9635 - accuracy: 0.3262\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.7445 - accuracy: 0.4378\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.5745 - accuracy: 0.5180\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.4408 - accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.3305 - accuracy: 0.6066\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2447 - accuracy: 0.6315\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.1708 - accuracy: 0.6539\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1120 - accuracy: 0.6690\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0615 - accuracy: 0.6840\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0230 - accuracy: 0.6927\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9804 - accuracy: 0.7069\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9485 - accuracy: 0.7140\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9175 - accuracy: 0.7235\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8904 - accuracy: 0.7311\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8625 - accuracy: 0.7385\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8439 - accuracy: 0.7445\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8214 - accuracy: 0.7496\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8011 - accuracy: 0.7543\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7847 - accuracy: 0.7606\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.7704 - accuracy: 0.7649\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7553 - accuracy: 0.7697\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.7368 - accuracy: 0.7733\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.7257 - accuracy: 0.7775\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.7169 - accuracy: 0.7806\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.7030 - accuracy: 0.7831\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.6954 - accuracy: 0.7881\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.6826 - accuracy: 0.7886\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.6694 - accuracy: 0.7927\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.6586 - accuracy: 0.7984\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.6588 - accuracy: 0.7982\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.6434 - accuracy: 0.8024\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.6345 - accuracy: 0.8042\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.6295 - accuracy: 0.8053\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.6246 - accuracy: 0.8064\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.6161 - accuracy: 0.8102\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.6036 - accuracy: 0.8141\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.6041 - accuracy: 0.8152\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.5959 - accuracy: 0.8171\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.5896 - accuracy: 0.8185\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.5827 - accuracy: 0.8197\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.5768 - accuracy: 0.8223\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.5711 - accuracy: 0.8223\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.5680 - accuracy: 0.8231\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.5581 - accuracy: 0.8277\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.5597 - accuracy: 0.8268\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.5517 - accuracy: 0.8306\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.5455 - accuracy: 0.8321\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.5416 - accuracy: 0.8328\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.5415 - accuracy: 0.8336\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.5325 - accuracy: 0.8350\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.5354 - accuracy: 0.8330\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.5295 - accuracy: 0.8357\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.5265 - accuracy: 0.8375\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.5182 - accuracy: 0.8379\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.5160 - accuracy: 0.8412\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.5136 - accuracy: 0.8405\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.5104 - accuracy: 0.8425\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.5054 - accuracy: 0.8435\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.5052 - accuracy: 0.8426\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4991 - accuracy: 0.8448\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4976 - accuracy: 0.8457\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4947 - accuracy: 0.8486\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4887 - accuracy: 0.8486\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4880 - accuracy: 0.8492\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4842 - accuracy: 0.8496\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4795 - accuracy: 0.8506\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4802 - accuracy: 0.8509\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4786 - accuracy: 0.8526\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4742 - accuracy: 0.8524\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4722 - accuracy: 0.8540\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4709 - accuracy: 0.8564\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4612 - accuracy: 0.8578\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4620 - accuracy: 0.8559\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4662 - accuracy: 0.8544\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4614 - accuracy: 0.8561\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4574 - accuracy: 0.8590\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4572 - accuracy: 0.8581\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4527 - accuracy: 0.8589\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4486 - accuracy: 0.8605\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4447 - accuracy: 0.8616\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4460 - accuracy: 0.8623\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4431 - accuracy: 0.8619\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4380 - accuracy: 0.8634\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4389 - accuracy: 0.8650\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4406 - accuracy: 0.8653\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4375 - accuracy: 0.8636\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4331 - accuracy: 0.8637\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4349 - accuracy: 0.8640\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.4307 - accuracy: 0.8669\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4301 - accuracy: 0.8660\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4277 - accuracy: 0.8655\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4250 - accuracy: 0.8665\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4284 - accuracy: 0.8657\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4205 - accuracy: 0.8694\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4160 - accuracy: 0.8701\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 0.4197 - accuracy: 0.8687\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.4143 - accuracy: 0.8717\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4135 - accuracy: 0.8714\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.4104 - accuracy: 0.8720\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(70, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(30, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "KYWl6BK5F-uA",
    "outputId": "a9838024-70dc-4373-c560-1335b55594ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 77us/sample - loss: 0.9435 - accuracy: 0.7306\n",
      "Test accuracy:  73.06 %\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)\n",
    "print('Test accuracy: ', round(results[1]*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TYfLXFV-kepr"
   },
   "source": [
    "Model 6: Adding Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MfKsR353KH-t"
   },
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(70, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(50, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(30, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(10, kernel_initializer='he_normal',bias_initializer='he_uniform'))\n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "        sgd = optimizers.SGD(lr = 0.01)\n",
    "        model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zzZmEnavKLUI",
    "outputId": "df52dfaa-aa2d-48ee-c40f-b9e188d1903d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.5600 - accuracy: 0.1199\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.3232 - accuracy: 0.1619\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.1943 - accuracy: 0.2055\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.0890 - accuracy: 0.2497\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 2.0064 - accuracy: 0.2869\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.9309 - accuracy: 0.3167\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.8775 - accuracy: 0.3419\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.8169 - accuracy: 0.3690\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.7620 - accuracy: 0.3880\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.7108 - accuracy: 0.4137\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.6755 - accuracy: 0.4301\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.6382 - accuracy: 0.4440\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.6033 - accuracy: 0.4570\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.5685 - accuracy: 0.4727\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.5376 - accuracy: 0.4842\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.5052 - accuracy: 0.4969\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.4893 - accuracy: 0.5062\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.4616 - accuracy: 0.5117\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.4388 - accuracy: 0.5211\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.4062 - accuracy: 0.5338\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 1.3961 - accuracy: 0.5365\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.3755 - accuracy: 0.5448\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.3639 - accuracy: 0.5483\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.3465 - accuracy: 0.5554\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.3331 - accuracy: 0.5609\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.3093 - accuracy: 0.5701\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2963 - accuracy: 0.5754\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2846 - accuracy: 0.5780\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2710 - accuracy: 0.5838\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.2569 - accuracy: 0.5875\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2464 - accuracy: 0.5923\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2319 - accuracy: 0.5978\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2297 - accuracy: 0.5996\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.2180 - accuracy: 0.6040\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.1955 - accuracy: 0.6087\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1931 - accuracy: 0.6117\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1775 - accuracy: 0.6203\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1744 - accuracy: 0.6195\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1660 - accuracy: 0.6228\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1580 - accuracy: 0.6253\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.1497 - accuracy: 0.6319\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1449 - accuracy: 0.6321\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1384 - accuracy: 0.6338\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1245 - accuracy: 0.6403\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.1190 - accuracy: 0.6404\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.1131 - accuracy: 0.6433\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.1026 - accuracy: 0.6490\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 1.0991 - accuracy: 0.6487\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0933 - accuracy: 0.6509\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0859 - accuracy: 0.6527\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0815 - accuracy: 0.6553\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0761 - accuracy: 0.6583\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0648 - accuracy: 0.6610\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0610 - accuracy: 0.6625\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 1.0556 - accuracy: 0.6619\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0469 - accuracy: 0.6670\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0482 - accuracy: 0.6674\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0379 - accuracy: 0.6737\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0292 - accuracy: 0.6727\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0262 - accuracy: 0.6728\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0256 - accuracy: 0.6755\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0155 - accuracy: 0.6776\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0175 - accuracy: 0.6788\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0064 - accuracy: 0.6816\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9977 - accuracy: 0.6829\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 1.0102 - accuracy: 0.6804\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9993 - accuracy: 0.6851\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9956 - accuracy: 0.6840\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9909 - accuracy: 0.6865\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9897 - accuracy: 0.6890\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9859 - accuracy: 0.6876\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9866 - accuracy: 0.6888\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9765 - accuracy: 0.6915\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9760 - accuracy: 0.6921\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9719 - accuracy: 0.6952\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9585 - accuracy: 0.6958\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9641 - accuracy: 0.6978\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9629 - accuracy: 0.6987\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9529 - accuracy: 0.6992\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 19us/sample - loss: 0.9607 - accuracy: 0.6988\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9481 - accuracy: 0.7018\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9396 - accuracy: 0.7048\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9462 - accuracy: 0.7026\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 0.9314 - accuracy: 0.7075\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9325 - accuracy: 0.7099\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9412 - accuracy: 0.7045\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9382 - accuracy: 0.7053\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9314 - accuracy: 0.7085\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9266 - accuracy: 0.7086\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9249 - accuracy: 0.7092\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9242 - accuracy: 0.7094\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9152 - accuracy: 0.7153\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9148 - accuracy: 0.7138\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9149 - accuracy: 0.7138\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9170 - accuracy: 0.7134\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9103 - accuracy: 0.7156\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.9001 - accuracy: 0.7196\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8973 - accuracy: 0.7200\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 0.9043 - accuracy: 0.7196\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8886 - accuracy: 0.7238\n"
     ]
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "p4m44wbNKsZe",
    "outputId": "03b87362-a5c7-475c-f7cf-615f3e9e69e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 76us/sample - loss: 0.7326 - accuracy: 0.7809\n",
      "Test accuracy:  78.09 %\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)\n",
    "print('Test accuracy: ', round(results[1]*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nHJwL4TlklR2"
   },
   "source": [
    "Model 7: Changing batch size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "R8eCdcluV2n1",
    "outputId": "d52a25d9-13ad-4d7a-e351-a5f0309927e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 4s 85us/sample - loss: 2.3598 - accuracy: 0.1554\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 2.0283 - accuracy: 0.2678\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 1.8572 - accuracy: 0.3395\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 1.7342 - accuracy: 0.3951\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 1.6313 - accuracy: 0.4373\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 1.5589 - accuracy: 0.4646\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 1.5033 - accuracy: 0.4911\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 3s 68us/sample - loss: 1.4572 - accuracy: 0.5055\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 3s 68us/sample - loss: 1.4106 - accuracy: 0.5273\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 3s 70us/sample - loss: 1.3751 - accuracy: 0.5422\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 3s 70us/sample - loss: 1.3468 - accuracy: 0.5526\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 3s 70us/sample - loss: 1.3102 - accuracy: 0.5671\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 3s 69us/sample - loss: 1.2861 - accuracy: 0.5770\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 1.2584 - accuracy: 0.5858\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 1.2343 - accuracy: 0.5927\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 1.2105 - accuracy: 0.6067\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 1.1899 - accuracy: 0.6123\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 1.1765 - accuracy: 0.6196\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 1.1657 - accuracy: 0.6224\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 1.1441 - accuracy: 0.6302\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 1.1230 - accuracy: 0.6399\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 1.1172 - accuracy: 0.6402\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 1.1060 - accuracy: 0.6456\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 1.0967 - accuracy: 0.6503\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 1.0797 - accuracy: 0.6550\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 1.0656 - accuracy: 0.6599\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 1.0666 - accuracy: 0.6601\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 1.0609 - accuracy: 0.6639\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 1.0451 - accuracy: 0.6705\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 1.0442 - accuracy: 0.6687\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 1.0267 - accuracy: 0.6725\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 3s 67us/sample - loss: 1.0291 - accuracy: 0.6724\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 1.0281 - accuracy: 0.6733\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 1.0156 - accuracy: 0.6796\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.9957 - accuracy: 0.6864\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 1.0021 - accuracy: 0.6842\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 1.0050 - accuracy: 0.6829\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.9952 - accuracy: 0.6840\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.9867 - accuracy: 0.6908\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.9836 - accuracy: 0.6908\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.9755 - accuracy: 0.6925\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.9686 - accuracy: 0.6948\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.9748 - accuracy: 0.6935\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.9649 - accuracy: 0.6950\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.9633 - accuracy: 0.6950\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 3s 68us/sample - loss: 0.9535 - accuracy: 0.7006\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 3s 67us/sample - loss: 0.9526 - accuracy: 0.7000\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.9519 - accuracy: 0.7020\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.9459 - accuracy: 0.7035\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.9352 - accuracy: 0.7062\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.9360 - accuracy: 0.7063\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.9308 - accuracy: 0.7077\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.9293 - accuracy: 0.7112\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.9296 - accuracy: 0.7103\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.9297 - accuracy: 0.7093\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.9255 - accuracy: 0.7094\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.9165 - accuracy: 0.7147\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.9175 - accuracy: 0.7131\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.9171 - accuracy: 0.7123\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.9128 - accuracy: 0.7157\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.9037 - accuracy: 0.7150\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.9083 - accuracy: 0.7140\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 3s 67us/sample - loss: 0.9037 - accuracy: 0.7195\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.9039 - accuracy: 0.7142\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8911 - accuracy: 0.7217\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8977 - accuracy: 0.7179\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.9010 - accuracy: 0.7203\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8984 - accuracy: 0.7200\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8908 - accuracy: 0.7215\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.9003 - accuracy: 0.7173\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8923 - accuracy: 0.7221\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8890 - accuracy: 0.7241\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8854 - accuracy: 0.7232\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8762 - accuracy: 0.7279\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8752 - accuracy: 0.7269\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8747 - accuracy: 0.7247\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8763 - accuracy: 0.7254\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.8767 - accuracy: 0.7245\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8722 - accuracy: 0.7267\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8733 - accuracy: 0.7270\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8668 - accuracy: 0.7256\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8749 - accuracy: 0.7282\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8680 - accuracy: 0.7311\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.8670 - accuracy: 0.7277\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8607 - accuracy: 0.7325\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.8702 - accuracy: 0.7293\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8637 - accuracy: 0.7291\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8633 - accuracy: 0.7315\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.8568 - accuracy: 0.7288\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8522 - accuracy: 0.7329\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8542 - accuracy: 0.7334\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8615 - accuracy: 0.7298\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.8542 - accuracy: 0.7351\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8536 - accuracy: 0.7323\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8524 - accuracy: 0.7332\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8502 - accuracy: 0.7360\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8460 - accuracy: 0.7350\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8484 - accuracy: 0.7365\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8396 - accuracy: 0.7395\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8491 - accuracy: 0.7356\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.8431 - accuracy: 0.7377\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8445 - accuracy: 0.7367\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8409 - accuracy: 0.7377\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8489 - accuracy: 0.7347\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.8405 - accuracy: 0.7411\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8402 - accuracy: 0.7376\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8402 - accuracy: 0.7364\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8440 - accuracy: 0.7367\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8300 - accuracy: 0.7406\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8397 - accuracy: 0.7387\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8345 - accuracy: 0.7397\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8348 - accuracy: 0.7374\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.8388 - accuracy: 0.7397\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8347 - accuracy: 0.7385\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8298 - accuracy: 0.7420\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8245 - accuracy: 0.7424\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8240 - accuracy: 0.7441\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8439 - accuracy: 0.7357\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8289 - accuracy: 0.7392\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8297 - accuracy: 0.7427\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.8327 - accuracy: 0.7399\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8283 - accuracy: 0.7412\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.8197 - accuracy: 0.7424\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 3s 69us/sample - loss: 0.8219 - accuracy: 0.7434\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 3s 68us/sample - loss: 0.8242 - accuracy: 0.7430\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 3s 68us/sample - loss: 0.8281 - accuracy: 0.7417\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 3s 69us/sample - loss: 0.8286 - accuracy: 0.7424\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8176 - accuracy: 0.7456\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8153 - accuracy: 0.7459\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8125 - accuracy: 0.7460\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8230 - accuracy: 0.7417\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8229 - accuracy: 0.7445\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8190 - accuracy: 0.7472\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8246 - accuracy: 0.7434\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8194 - accuracy: 0.7457\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8177 - accuracy: 0.7453\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.8223 - accuracy: 0.7436\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.8151 - accuracy: 0.7472\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8152 - accuracy: 0.7480\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8225 - accuracy: 0.7432\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8079 - accuracy: 0.7466\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8073 - accuracy: 0.7485\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8162 - accuracy: 0.7443\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.8106 - accuracy: 0.7483\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.8107 - accuracy: 0.7482\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8075 - accuracy: 0.7500\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8139 - accuracy: 0.7453\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8094 - accuracy: 0.7465\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8077 - accuracy: 0.7487\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8069 - accuracy: 0.7480\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8071 - accuracy: 0.7489\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8059 - accuracy: 0.7486\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8070 - accuracy: 0.7485\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8059 - accuracy: 0.7488\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8007 - accuracy: 0.7514\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8111 - accuracy: 0.7486\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8047 - accuracy: 0.7492\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.7911 - accuracy: 0.7540\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8098 - accuracy: 0.7470\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.7971 - accuracy: 0.7504\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8019 - accuracy: 0.7492\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 3s 66us/sample - loss: 0.8049 - accuracy: 0.7492\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8048 - accuracy: 0.7501\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8020 - accuracy: 0.7510\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.7987 - accuracy: 0.7502\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.7994 - accuracy: 0.7510\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.8071 - accuracy: 0.7510\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8056 - accuracy: 0.7487\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.7984 - accuracy: 0.7515\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.8028 - accuracy: 0.7507\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.7981 - accuracy: 0.7498\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.8007 - accuracy: 0.7489\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.7985 - accuracy: 0.7523\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.7969 - accuracy: 0.7540\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.7933 - accuracy: 0.7550\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.7968 - accuracy: 0.7533\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.7966 - accuracy: 0.7561\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.7968 - accuracy: 0.7520\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.7948 - accuracy: 0.7502\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.7946 - accuracy: 0.7510\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.7970 - accuracy: 0.7520\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.7986 - accuracy: 0.7537\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.7961 - accuracy: 0.7537\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.7970 - accuracy: 0.7503\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.7993 - accuracy: 0.7500\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.7971 - accuracy: 0.7545\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.7942 - accuracy: 0.7558\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.7923 - accuracy: 0.7538\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.7951 - accuracy: 0.7538\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.7960 - accuracy: 0.7534\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.7877 - accuracy: 0.7548\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.7931 - accuracy: 0.7542\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.7857 - accuracy: 0.7538\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.7811 - accuracy: 0.7574\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.7893 - accuracy: 0.7525\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.7863 - accuracy: 0.7552\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.7819 - accuracy: 0.7558\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.7909 - accuracy: 0.7549\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.7833 - accuracy: 0.7569\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.7920 - accuracy: 0.7549\n"
     ]
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, batch_size = 50, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "xhRazU7pW2ex",
    "outputId": "74afab09-bf69-42ee-be53-1fc5554ec4c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 77us/sample - loss: 0.6161 - accuracy: 0.8147\n",
      "Test accuracy:  81.47 %\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val, y_val)\n",
    "print('Test accuracy: ', round(results[1]*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OvAJXjYKkqmM"
   },
   "source": [
    "Preditcing values for test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1th5U5HYXo4K"
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IKMaHxO_Xxwx"
   },
   "outputs": [],
   "source": [
    "X_test_plt = X_val.reshape(X_val.shape[0], 32,32)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(X_test_plt[365])    \n",
    "plt.show()\n",
    "print('Label: ', y_val[365])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zt9yTNXBkyMO"
   },
   "source": [
    "Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "colab_type": "code",
    "id": "gUfGvCGibf-a",
    "outputId": "19f140d4-7655-4151-84f1-0d755928660b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>46.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN</td>\n",
       "      <td>81.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Type  Test Score\n",
       "0        KNN       46.00\n",
       "1         NN       81.65"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names =  ['Model Type', 'Test Score']\n",
    "model_comparison  = pd.DataFrame(columns = col_names)\n",
    "model_comparison.loc[len(model_comparison)] = 'KNN', round(0.46*100,2)\n",
    "model_comparison.loc[len(model_comparison)] = 'NN', round(0.8165*100,2)\n",
    "model_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t14BlChWow1-"
   },
   "source": [
    "We can see that for KNN Classifier, the accuracy in Test set is about 46% while that for a Neural Network is 81%. It is almost double the accuracy when we are using a fully connected Neural Network. Also, due to the large volume of data, both in height and width, the KNN took a long time to execute, while NN was very faster.\n",
    "\n",
    "We can conclude that Neural Networks works better for such image classification problem than traditional KNN, in terms of performance and accuracy both."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
